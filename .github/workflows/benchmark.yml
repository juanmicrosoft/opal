name: Benchmarks

on:
  # Run on releases - includes all benchmarks (LLM included)
  release:
    types: [created]
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      statistical_runs:
        description: 'Number of statistical runs (default 30)'
        required: false
        default: '30'
      skip_llm:
        description: 'Skip LLM benchmarks (faster, cheaper)'
        required: false
        default: 'false'
        type: boolean
      agent_refactoring:
        description: 'Run agent refactoring benchmark'
        required: false
        default: 'false'
        type: boolean
  # Run on pushes to benchmark-related files
  push:
    branches: [main]
    paths:
      - 'tests/Calor.Evaluation/**'
      - 'tests/TestData/Benchmarks/**'
      - 'tests/E2E/agent-tasks/**'
      - '.github/workflows/benchmark.yml'

jobs:
  benchmark:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '8.0.x'

      - name: Restore dependencies
        run: dotnet restore

      - name: Build
        run: dotnet build -c Release --no-restore

      - name: Run static benchmarks
        run: |
          dotnet run --project tests/Calor.Evaluation -c Release -- run \
            --format website \
            --output website/public/data/benchmark-results.json \
            --verbose

      - name: Run statistical analysis
        if: github.event.inputs.statistical_runs != ''
        run: |
          RUNS="${{ github.event.inputs.statistical_runs || '30' }}"
          dotnet run --project tests/Calor.Evaluation -c Release -- run \
            --statistical \
            --runs "$RUNS" \
            --format website \
            --output website/public/data/benchmark-results-statistical.json \
            --verbose

      # LLM Benchmarks - run on release, or when not skipped in manual trigger
      - name: Restore LLM response cache
        if: github.event_name == 'release' || (github.event_name == 'workflow_dispatch' && github.event.inputs.skip_llm != 'true')
        uses: actions/cache@v4
        with:
          path: ~/.calor/llm-cache
          key: llm-cache-${{ github.run_id }}
          restore-keys: |
            llm-cache-

      - name: Run TaskCompletion benchmark (LLM)
        if: github.event_name == 'release' || (github.event_name == 'workflow_dispatch' && github.event.inputs.skip_llm != 'true')
        continue-on-error: true
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          if [ -z "$ANTHROPIC_API_KEY" ]; then
            echo "::warning::ANTHROPIC_API_KEY not set, skipping LLM benchmarks"
            exit 0
          fi
          dotnet run --project tests/Calor.Evaluation -c Release -- llm-tasks \
            -m tests/Calor.Evaluation/Tasks/task-manifest.json \
            --budget 5.00 \
            --output website/public/data/llm-results.json \
            --verbose

      - name: Run Safety benchmark (LLM)
        if: github.event_name == 'release' || (github.event_name == 'workflow_dispatch' && github.event.inputs.skip_llm != 'true')
        continue-on-error: true
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          if [ -z "$ANTHROPIC_API_KEY" ]; then
            exit 0
          fi
          dotnet run --project tests/Calor.Evaluation -c Release -- safety-benchmark \
            -m tests/Calor.Evaluation/Tasks/task-manifest-safety.json \
            --budget 5.00 \
            --output website/public/data/safety-results.json \
            --verbose

      - name: Run EffectDiscipline benchmark (LLM)
        if: github.event_name == 'release' || (github.event_name == 'workflow_dispatch' && github.event.inputs.skip_llm != 'true')
        continue-on-error: true
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          if [ -z "$ANTHROPIC_API_KEY" ]; then
            exit 0
          fi
          dotnet run --project tests/Calor.Evaluation -c Release -- effect-discipline \
            -m tests/Calor.Evaluation/Tasks/task-manifest-effects.json \
            --budget 5.00 \
            --output website/public/data/effect-discipline-results.json \
            --verbose

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Merge LLM results into benchmark-results.json
        if: github.event_name == 'release' || (github.event_name == 'workflow_dispatch' && github.event.inputs.skip_llm != 'true')
        run: |
          node scripts/merge-llm-results.js

      - name: Generate HTML dashboard
        run: |
          dotnet run --project tests/Calor.Evaluation -c Release -- run \
            --format html \
            --output website/public/data/dashboard

      - name: Generate docs/benchmarking/results.md
        run: node scripts/generate-results-md.js

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            website/public/data/benchmark-results.json
            website/public/data/benchmark-results-statistical.json
            website/public/data/llm-results.json
            website/public/data/safety-results.json
            website/public/data/effect-discipline-results.json
            website/public/data/dashboard.html
          retention-days: 90

      - name: Create PR with benchmark results
        if: github.ref == 'refs/heads/main' || github.event_name == 'release' || github.event_name == 'workflow_dispatch'
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "chore: update benchmark results"
          title: "chore: Update benchmark results"
          body: |
            This PR updates the benchmark results.

            ## Changes
            - Updated benchmark-results.json with latest metrics
            - Generated HTML dashboard
            - Updated docs/benchmarking/results.md

            ## Metrics
            Run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          branch: benchmark-results-update
          base: main
          delete-branch: true

  regression-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    needs: benchmark

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Download current results
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results
          path: current-results

      - name: Check for regression
        run: |
          echo "Checking for benchmark regressions..."
          if [ -f "current-results/benchmark-results.json" ]; then
            echo "Benchmark results generated successfully"
            cat current-results/benchmark-results.json | head -50
          else
            echo "Warning: No benchmark results found"
          fi

  # Agent Refactoring Benchmark - compares Calor vs C# refactoring success rates
  # Uses Claude Code CLI to perform refactoring tasks and measures pass rates
  agent-refactoring-benchmark:
    runs-on: ubuntu-latest
    if: github.event_name == 'release' || github.event.inputs.agent_refactoring == 'true'
    needs: benchmark
    permissions:
      contents: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '8.0.x'

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Claude Code CLI
        run: npm install -g @anthropic-ai/claude-code

      - name: Install jq
        run: sudo apt-get install -y jq

      - name: Restore dependencies
        run: dotnet restore

      - name: Build compiler
        run: dotnet build -c Release --no-restore

      - name: Run Calor refactoring benchmark
        id: calor-benchmark
        continue-on-error: true
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          cd tests/E2E/agent-tasks
          chmod +x run-agent-tests.sh
          ./run-agent-tests.sh --category refactoring-benchmark --filter calor --single-run 2>&1 | tee /tmp/calor-results.txt
          # Extract pass rate
          CALOR_PASS_RATE=$(grep -oP 'Pass Rate: \K[0-9]+' /tmp/calor-results.txt || echo "0")
          echo "calor_pass_rate=$CALOR_PASS_RATE" >> $GITHUB_OUTPUT

      - name: Run C# refactoring benchmark
        id: csharp-benchmark
        continue-on-error: true
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          cd tests/E2E/agent-tasks
          ./run-agent-tests.sh --category refactoring-benchmark --filter csharp --single-run 2>&1 | tee /tmp/csharp-results.txt
          # Extract pass rate
          CSHARP_PASS_RATE=$(grep -oP 'Pass Rate: \K[0-9]+' /tmp/csharp-results.txt || echo "0")
          echo "csharp_pass_rate=$CSHARP_PASS_RATE" >> $GITHUB_OUTPUT

      - name: Generate agent benchmark results JSON
        run: |
          mkdir -p website/public/data
          cat > website/public/data/agent-refactoring-results.json << EOF
          {
            "version": "1.0.0",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "commit": "${{ github.sha }}",
            "benchmark": "agent-refactoring",
            "description": "Measures Claude Code agent success rates on refactoring tasks",
            "results": {
              "calor": {
                "passRate": ${{ steps.calor-benchmark.outputs.calor_pass_rate || 0 }},
                "tasksTotal": 20,
                "category": "refactoring-benchmark"
              },
              "csharp": {
                "passRate": ${{ steps.csharp-benchmark.outputs.csharp_pass_rate || 0 }},
                "tasksTotal": 20,
                "category": "refactoring-benchmark"
              }
            },
            "methodology": {
              "votingMode": "single-run",
              "agent": "claude-code",
              "verification": ["compilation", "z3-contracts"]
            }
          }
          EOF

      - name: Upload agent benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: agent-refactoring-results
          path: website/public/data/agent-refactoring-results.json
          retention-days: 90

      - name: Commit agent benchmark results
        if: github.ref == 'refs/heads/main'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git pull --rebase origin main || true
          git add website/public/data/agent-refactoring-results.json || true
          git diff --staged --quiet || git commit -m "chore: Update agent refactoring benchmark results [skip ci]"
          git push || echo "No changes to push"

      - name: Report benchmark summary
        run: |
          echo "## Agent Refactoring Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Language | Pass Rate |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|-----------|" >> $GITHUB_STEP_SUMMARY
          echo "| Calor | ${{ steps.calor-benchmark.outputs.calor_pass_rate || 'N/A' }}% |" >> $GITHUB_STEP_SUMMARY
          echo "| C# | ${{ steps.csharp-benchmark.outputs.csharp_pass_rate || 'N/A' }}% |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The agent refactoring benchmark measures Claude Code's ability to perform" >> $GITHUB_STEP_SUMMARY
          echo "refactoring tasks (rename, extract, inline, move, add contracts, change signature)" >> $GITHUB_STEP_SUMMARY
          echo "on both Calor and C# codebases." >> $GITHUB_STEP_SUMMARY
